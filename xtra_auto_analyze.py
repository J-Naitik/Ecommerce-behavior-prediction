"""
auto_analyze.py
Automated analysis of outputs produced by the e-commerce pipeline.
Generates:
 - analysis_report.md (human-readable)
 - analysis_outputs/ (plots + small csv summaries)

Usage:
  python auto_analyze.py --project_root /full/path/to/project
"""

import os
import argparse
import json
from pathlib import Path
import numpy as np
import pandas as pd

# plotting
import matplotlib.pyplot as plt
import seaborn as sns

# model loading
import joblib
from sklearn.metrics import confusion_matrix
from sklearn.decomposition import PCA

# ============================================================
# Utility functions
# ============================================================

def safe_read_csv(path):
    """Return DataFrame or None, never raise."""
    try:
        if Path(path).exists():
            return pd.read_csv(path)
        return None
    except Exception as e:
        print(f"[!] Could not read {path}: {e}")
        return None


def try_paths(*paths):
    """Try multiple file paths and return first successful DataFrame."""
    for p in paths:
        df = safe_read_csv(p)
        if df is not None:
            return df
    return None


def basic_data_checks(df):
    out = {}
    out["rows"] = len(df)
    out["cols"] = len(df.columns)
    out["missing_counts"] = df.isna().sum().to_dict()
    out["dtypes"] = df.dtypes.astype(str).to_dict()
    numcols = df.select_dtypes(include=["number"]).columns
    out["numeric_summary"] = df[numcols].describe().to_dict()
    return out


def write_md_report(path, sections):
    with open(path, "w", encoding="utf-8") as f:
        f.write("# Automated Analysis Report\n\n")
        f.write("Generated by auto_analyze.py\n\n")
        for title, body in sections:
            f.write(f"## {title}\n\n{body}\n\n")


# ============================================================
# Plotting utilities
# ============================================================

def plot_and_save_confusion(cm, labels, outdir):
    fig, ax = plt.subplots(figsize=(4, 4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", ax=ax,
                xticklabels=labels, yticklabels=labels)
    ax.set_xlabel("Predicted")
    ax.set_ylabel("Actual")
    plt.tight_layout()
    out = Path(outdir) / "confusion_matrix_recreated.png"
    fig.savefig(out)
    plt.close(fig)
    return str(out)


def plot_feature_importance(names, vals, outdir):
    df = pd.DataFrame({"feature": names, "importance": vals})
    df = df.sort_values("importance", ascending=False).head(20)

    fig, ax = plt.subplots(figsize=(6, 0.3 * len(df) + 4))
    sns.barplot(x="importance", y="feature", data=df, ax=ax)
    ax.set_title("Feature Importance (Top 20)")
    plt.tight_layout()

    p = Path(outdir) / "feature_importance_recreated.png"
    fig.savefig(p)
    plt.close(fig)
    return df, str(p)


def plot_transaction_distribution(df, outdir):
    if df is None:
        return None
    if "user_id" in df.columns:
        counts = df.groupby("user_id").size()
    else:
        return None

    fig, ax = plt.subplots(figsize=(6, 4))
    sns.histplot(counts, bins=30, kde=False, ax=ax)
    ax.set_xlabel("Purchases per User")
    ax.set_ylabel("Number of Users")
    plt.tight_layout()

    p = Path(outdir) / "transaction_distribution_recreated.png"
    fig.savefig(p)
    plt.close(fig)
    return str(p)


def plot_correlation_heatmap(df, outdir):
    if df is None:
        return None
    num_df = df.select_dtypes(include=["number"])
    if num_df.shape[1] < 2:
        return None

    corr = num_df.corr()
    fig, ax = plt.subplots(figsize=(10, 8))
    sns.heatmap(corr, cmap="vlag", center=0, ax=ax)
    plt.tight_layout()

    p = Path(outdir) / "correlation_heatmap_recreated.png"
    fig.savefig(p)
    plt.close(fig)
    return str(p), corr


def plot_segment_distribution(df, outdir):
    if df is None:
        return None

    col = None
    for c in ["segment", "cluster"]:
        if c in df.columns:
            col = c
            break

    if col is None:
        return None

    counts = df[col].value_counts().sort_index()

    fig, ax = plt.subplots(figsize=(6, 4))
    counts.plot(kind="bar", ax=ax)
    ax.set_xlabel("Segment")
    ax.set_ylabel("Users")
    plt.tight_layout()

    p = Path(outdir) / "segment_distribution_recreated.png"
    fig.savefig(p)
    plt.close(fig)

    return str(p), counts.to_dict()


def plot_segment_scatter(features, segments, outdir):
    if features is None or len(features) < 2:
        return None

    num = features.select_dtypes(include=["number"]).fillna(0)
    pca = PCA(n_components=2)
    coords = pca.fit_transform(num)
    df = pd.DataFrame(coords, columns=["pc1", "pc2"], index=features.index)

    if segments is not None and "user_id" in segments.columns:
        df = df.join(segments.set_index("user_id"), how="left")

    fig, ax = plt.subplots(figsize=(6, 5))
    if "segment" in df.columns:
        sns.scatterplot(data=df, x="pc1", y="pc2", hue="segment", s=25, palette="tab10", ax=ax)
    else:
        sns.scatterplot(data=df, x="pc1", y="pc2", s=25, ax=ax)

    plt.tight_layout()
    p = Path(outdir) / "customer_segments_recreated.png"
    fig.savefig(p)
    plt.close(fig)
    return str(p)


# ============================================================
# Interpretation helpers
# ============================================================

def interpret_confusion(cm):
    tn, fp, fn, tp = cm.ravel()
    total = cm.sum()

    accuracy = (tp + tn) / total
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0

    text = [
        f"- Accuracy: {accuracy:.3f}",
        f"- Precision: {precision:.3f}",
        f"- Recall: {recall:.3f}",
        f"- F1 Score: {f1:.3f}",
        f"- False Negatives: {fn}",
    ]

    if fn > tp:
        text.append("⚠️ Warning: FN > TP — model misses many buyers.")

    return "\n".join(text)


def interpret_feature_importance(df):
    lines = ["Top important features:"]
    for _, row in df.head(7).iterrows():
        lines.append(f"- {row['feature']} (importance={row['importance']:.4f})")
    return "\n".join(lines)


# ============================================================
# Main
# ============================================================

def main(args):
    root = Path(args.project_root)
    outdir = root / "analysis_outputs"
    outdir.mkdir(exist_ok=True)

    sections = []

    # --------------------------
    # 1. Load data files
    # --------------------------
    users = try_paths(root/"data/users.csv", root/"users.csv")
    products = try_paths(root/"data/products.csv", root/"products.csv")
    transactions = try_paths(root/"data/transactions.csv", root/"transactions.csv")
    features = try_paths(root/"output/user_features.csv", root/"user_features.csv")
    segments = try_paths(root/"output/customer_segments.csv", root/"customer_segments.csv")

    # metrics JSON
    metrics = None
    for p in [root/"output/model_metrics.json", root/"model_metrics.json"]:
        if p.exists():
            metrics = json.load(open(p, "r", encoding="utf-8"))
            break

    # --------------------------
    # Data summary
    # --------------------------
    summary_lines = []
    for df, name in [
        (users, "users.csv"),
        (products, "products.csv"),
        (transactions, "transactions.csv"),
        (features, "user_features.csv"),
    ]:
        if df is None:
            summary_lines.append(f"- {name}: NOT FOUND")
        else:
            info = basic_data_checks(df)
            json.dump(info, open(outdir / f"summary_{name.replace('.','_')}.json", "w"),
                      indent=2, default=str)
            summary_lines.append(f"- {name}: rows={info['rows']}, cols={info['cols']}")

    sections.append(("Data Quality Summary", "\n".join(summary_lines)))

    # --------------------------
    # Transaction dist
    # --------------------------
    tplot = plot_transaction_distribution(transactions, outdir)
    sections.append(("Transaction Distribution", tplot or "Not available"))

    # --------------------------
    # Correlation heatmap
    # --------------------------
    if features is not None:
        heat = plot_correlation_heatmap(features, outdir)
        if heat:
            path, corr = heat
            high = [(i, j, float(corr.loc[i, j]))
                    for i in corr.columns for j in corr.columns
                    if i < j and abs(corr.loc[i, j]) > 0.8]
            sections.append(("Correlation Heatmap", f"Saved: {path}\nHigh correlations: {high[:10]}"))
        else:
            sections.append(("Correlation Heatmap", "Not available"))
    else:
        sections.append(("Correlation Heatmap", "Not available"))

    # --------------------------
    # Segments
    # --------------------------
    seg = plot_segment_distribution(segments, outdir)
    if isinstance(seg, tuple):
        img, counts = seg
        sections.append(("Segment Distribution", f"Saved: {img}\nCounts: {counts}"))
    else:
        sections.append(("Segment Distribution", seg or "Not available"))

    scatter = plot_segment_scatter(features, segments, outdir)
    sections.append(("Segment Scatter (PCA)", scatter or "Not available"))

    # --------------------------
    # Model evaluation
    # --------------------------
    model_lines = []

    # possible model files
    model_paths = [
        root/"models/purchase_model.pkl",
        root/"purchase_model.pkl",
        root/"models/purchase_model.joblib",
    ]

    model = None
    for p in model_paths:
        if p.exists():
            try:
                model = joblib.load(p)
                model_lines.append(f"Loaded model: {p}")
                break
            except Exception as e:
                model_lines.append(f"Found {p} but failed to load: {e}")

    # metrics json
    if metrics:
        model_lines.append("Metrics JSON loaded:\n" + json.dumps(metrics, indent=2))
    else:
        model_lines.append("Metrics JSON not found.")

    # recompute confusion matrix if target exists
    if model is not None and features is not None:
        target = None
        for col in ["will_purchase", "purchase", "label", "target"]:
            if col in features.columns:
                target = col
                break

        if target:
            X = features.drop(columns=[target]).fillna(0)
            y = features[target]

            try:
                pred = model.predict(X)
                cm = confusion_matrix(y, pred)
                cm_path = plot_and_save_confusion(cm, [0, 1], outdir)
                model_lines.append("Confusion matrix saved: " + cm_path)
                model_lines.append(interpret_confusion(cm))

                if hasattr(model, "feature_importances_"):
                    df_fi, fimg = plot_feature_importance(X.columns, model.feature_importances_, outdir)
                    model_lines.append("Feature importance saved: " + fimg)
                    model_lines.append(interpret_feature_importance(df_fi))

            except Exception as e:
                model_lines.append("Failed model eval: " + str(e))
        else:
            model_lines.append("No target column found for re-evaluation.")
    else:
        model_lines.append("Model or features missing; skipping evaluation.")

    sections.append(("Model Analysis", "\n\n".join(model_lines)))

    # --------------------------
    # Recommendations
    # --------------------------
    recs = try_paths(root/"output/recommendations.csv", root/"recommendations.csv")
    if recs is not None:
        preview = recs.head(20).to_dict(orient="records")
        sections.append(("Recommendations Sample", json.dumps(preview, indent=2)))
    else:
        sections.append(("Recommendations Sample", "Not available"))

    # --------------------------
    # Final report
    # --------------------------
    report_path = root / "analysis_report.md"
    write_md_report(report_path, sections)

    print(f"Analysis complete → {report_path}")
    print(f"Outputs saved in: {outdir}")


# ============================================================
# Entry point
# ============================================================

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--project_root", required=True)
    args = parser.parse_args()
    main(args)
